{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41fff4b9-9169-4890-affc-cbb9d1da92d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:25:44.845540: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-01 17:25:44.952040: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-01 17:25:44.953492: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-01 17:25:46.640301: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3211392   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17926209 (68.38 MB)\n",
      "Trainable params: 3211521 (12.25 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n",
      "Loaded 253 images with shape (253, 224, 224, 3)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:25:57.520630: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 128450560 exceeds 10% of free system memory.\n",
      "2024-08-01 17:25:57.756436: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 128450560 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 14s - loss: 4.1048 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:26:02.766172: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 822083584 exceeds 10% of free system memory.\n",
      "2024-08-01 17:26:04.548086: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 822083584 exceeds 10% of free system memory.\n",
      "2024-08-01 17:26:09.404668: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 205520896 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 73s 33s/step - loss: 15.2555 - accuracy: 0.5290\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 92s 28s/step - loss: 13.4182 - accuracy: 0.6771\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 63s 16s/step - loss: 7.3036 - accuracy: 0.6957\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 62s 28s/step - loss: 4.1703 - accuracy: 0.7826\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 92s 30s/step - loss: 5.1187 - accuracy: 0.7812\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 60s 16s/step - loss: 3.5311 - accuracy: 0.8188\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 80s 26s/step - loss: 2.6113 - accuracy: 0.8073\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 60s 16s/step - loss: 3.2610 - accuracy: 0.7609\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 80s 26s/step - loss: 2.3210 - accuracy: 0.8281\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 57s 15s/step - loss: 3.6703 - accuracy: 0.7971\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "datadir = os.path.join('.', 'dataset', 'brain_tumor_dataset')\n",
    "\n",
    "def resize_and_padding(image, target_size):\n",
    "    image = image.resize(target_size, Image.LANCZOS)\n",
    "    return image\n",
    "\n",
    "def convert_to_array(image):\n",
    "    return np.array(image)\n",
    "\n",
    "def load_and_preprocess(datadir, target_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in ['yes', 'no']:\n",
    "        folder_path = os.path.join(datadir, label)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = resize_and_padding(image, target_size)\n",
    "            image = convert_to_array(image)\n",
    "            image = preprocess_input(image)  # Use VGG16 preprocessing\n",
    "            images.append(image)\n",
    "            labels.append(1 if label == 'yes' else 0)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    print(f\"Loaded {len(images)} images with shape {images.shape}\")\n",
    "    return images, labels\n",
    "\n",
    "def split_data(images, labels, test_size=0.2, random_state=42):\n",
    "    return train_test_split(images, labels, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def create_data_generator(train_data, val_data, batch_size):\n",
    "    train_images, train_labels = train_data\n",
    "    val_images, val_labels = val_data\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    val_datagen = ImageDataGenerator()\n",
    "    \n",
    "    train_generator = train_datagen.flow(\n",
    "        train_images, train_labels,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    val_generator = val_datagen.flow(\n",
    "        val_images, val_labels,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator\n",
    "\n",
    "def build_CNN_with_TL(input_shape):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)  # Enable dropout\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "model = build_CNN_with_TL(input_shape)\n",
    "model.summary()\n",
    "\n",
    "images, labels = load_and_preprocess(datadir)\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = split_data(images, labels)\n",
    "\n",
    "batch_size = 64\n",
    "train_data = (train_images, train_labels)\n",
    "val_data = (val_images, val_labels)\n",
    "\n",
    "train_generator, validation_generator = create_data_generator(\n",
    "    train_data, val_data, batch_size\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_images) // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(val_images) // batch_size,\n",
    "    epochs=10   \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "176e3bae-f6ae-434d-9d07-2f2f39421f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sardar/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('TF_brain_tumor_detection_model.h5')\n",
    "\n",
    "def predict(image):\n",
    "    image = resize_and_padding(image, (224, 224))  # Ensure the target size matches your model's input\n",
    "    image = convert_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    prediction = model.predict(image)\n",
    "    return 'Tumor' if prediction[0] > 0.5 else 'No Tumor'\n",
    "\n",
    "model = tf.keras.models.load_model('TF_brain_tumor_detection_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e239cd7-5870-4f91-b2a1-994ffce8fc73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
